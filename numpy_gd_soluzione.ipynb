{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python37464bitbaseconda23e937e95969445babd8b9c091f71447",
      "display_name": "Python 3.7.4 64-bit ('base': conda)"
    },
    "colab": {
      "name": "numpy_gd.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg8sW2xRj6oV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ_sGZDqj6ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "n = 10_000\n",
        "f_minus_1 = 3\n",
        "\n",
        "bias = 4\n",
        "\n",
        "X = np.random.rand(n, f_minus_1)\n",
        "X = np.hstack((np.ones((n, 1)), X))\n",
        "y = X@np.array([[1], [2], [3], [4]]) + np.random.randn(n, 1)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ogevq9okwsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "715afece-1d6e-45ab-8130-9c3016016555"
      },
      "source": [
        "X[:5]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.5488135 , 0.71518937, 0.60276338],\n",
              "       [1.        , 0.54488318, 0.4236548 , 0.64589411],\n",
              "       [1.        , 0.43758721, 0.891773  , 0.96366276],\n",
              "       [1.        , 0.38344152, 0.79172504, 0.52889492],\n",
              "       [1.        , 0.56804456, 0.92559664, 0.07103606]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4Xidv3Uj6oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gradient(X_batch, y_batch, w):\n",
        "    ''' Ritorna il gradiente della loss MSE\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    X (np.array n x f): sotto-matrice delle features (batch?)\n",
        "    y (np.array n): targets associati\n",
        "    w (np.array f): parametri\n",
        "\n",
        "    Ret\n",
        "    ---\n",
        "    gradient (np.array)\n",
        "    '''\n",
        "    # vettore colonna\n",
        "    assert y_batch.ndim == 2 and y_batch.shape[1]==1\n",
        "    assert w.ndim == 2 and w.shape[1]==1\n",
        "\n",
        "    return ((w.T@X_batch.T@X_batch)*2 - (y_batch.T@X_batch)*2).T"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoCUFF_Pj6on",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generatore\n",
        "def get_batch(X, y, batch_size):\n",
        "    ''' Ritorna in sequenza i batch.\n",
        "    L'ultimo può essere meno numeroso di batch_size\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    X (np.array n x f): matrice delle features\n",
        "    y (np.array n): targets\n",
        "    batch_size: numero di campioni per batch\n",
        "\n",
        "    Yield\n",
        "    ------\n",
        "    (X_batch, y_batch)\n",
        "    X_batch (np.array batch_size x f): features del batch\n",
        "    y_batch (np.array batch_size): targets del batch\n",
        "    '''\n",
        "    idx = 0\n",
        "    while idx < X.shape[0]:\n",
        "        yield(X[idx:idx+batch_size], y[idx:idx+batch_size])\n",
        "        idx += batch_size"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBbXW_kfj6ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_regression_grad_desc(X, y, w_0, lr, eps, max_epochs, batch_size):\n",
        "    ''' Esegue un gradient descent\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    X (np.array n x f): matrice delle features\n",
        "    y (np.array n): targets\n",
        "    w_0 (np.array f): parametri iniziali\n",
        "    lr: learning rate\n",
        "    eps: convergenza se |w_n-w_(n-1)|< eps\n",
        "    max_epochs: numero massimo di epoche (si interrompe anche senza convergenza)\n",
        "    batch_size: numero di campioni per batch\n",
        "\n",
        "    Ret\n",
        "    ---\n",
        "    (convergence, w)\n",
        "    convergence: bool. Se è stata raggiunta la convergenza\n",
        "    w: i parametri finali\n",
        "    '''\n",
        "    # vettori colonna\n",
        "    assert y.ndim == 2 and y.shape[1]==1\n",
        "    assert w_0.ndim == 2 and w_0.shape[1]==1\n",
        "\n",
        "    convergence = False\n",
        "    w = np.copy(w_0)\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        w_start = np.copy(w)\n",
        "        for X_batch, y_batch in get_batch(X, y, batch_size):\n",
        "            gradient = get_gradient(X_batch, y_batch, w)\n",
        "            w -= gradient * lr\n",
        "        # finita epoca\n",
        "        if np.sqrt((w-w_start).T@(w-w_start)) < eps:\n",
        "            convergence = True\n",
        "            break\n",
        "\n",
        "    return convergence, w"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn4kwwkJj6ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv, w = linear_regression_grad_desc(X, y, w_0=np.zeros((4, 1)), lr=1e-3, eps=1e-15, max_epochs=1000, batch_size=32)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZntcBq2zcDJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "50642771-e06e-44e6-a94d-3da4ba2e2dcb"
      },
      "source": [
        "conv"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83Ntn0d42N_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "be331930-3e11-454c-8ea7-0155cee9117e"
      },
      "source": [
        "w"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.06908631],\n",
              "       [1.95320149],\n",
              "       [2.94743193],\n",
              "       [4.0026106 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aJlfcUj2Oxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 62,
      "outputs": []
    }
  ]
}